# Meeting Transcriber - Dependencies
# Lean stack: FastAPI + Whisper with GPU acceleration

# Web framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6
jinja2==3.1.2
aiofiles==23.2.1
python-dotenv==1.0.0

# Whisper (CPU - always installed)
faster-whisper==1.0.1

# ============================================
# GPU ACCELERATION (Optional - pick your platform)
# ============================================

# --- Mac (Apple Silicon M1/M2/M3) ---
# Uncomment to enable MLX acceleration (~3-5x faster):
# mlx>=0.5.0
# mlx-whisper>=0.1.0

# --- Windows/Linux (NVIDIA GPU) ---
# Uncomment to enable CUDA acceleration (~5-10x faster):
# torch>=2.0.0
# nvidia-cublas-cu12
# nvidia-cudnn-cu12

# ============================================
# SPEAKER DIARIZATION (Optional)
# ============================================
# Requires HuggingFace token - set HF_TOKEN in .env
# pip install git+https://github.com/m-bain/whisperX.git
